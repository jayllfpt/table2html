{"cells":[{"cell_type":"code","execution_count":55,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"1sAQ139ekiPcAd-ceBW8AJR2DtKYaWGab"},"executionInfo":{"elapsed":42094,"status":"ok","timestamp":1727495520962,"user":{"displayName":"Pham Phu Ngoc Trai (K16_HCM)","userId":"01599433814758632935"},"user_tz":-420},"id":"cD05NODtLQ6w","outputId":"68180ba3-af83-4097-8dd2-012c0bc95466"},"outputs":[{"name":"stdout","output_type":"stream","text":["Couldn't find program: 'bash'\n"]}],"source":["%%bash\n","# wget https://huggingface.co/datasets/bsmock/pubtables-1m/resolve/main/PubTables-1M-Structure_Annotations_Val.tar.gz\n","# wget https://huggingface.co/datasets/bsmock/pubtables-1m/resolve/main/PubTables-1M-Structure_Images_Val.tar.gz"]},{"cell_type":"code","execution_count":56,"metadata":{"colab":{"base_uri":"https://localhost:8080/","output_embedded_package_id":"18FbpO7LuFphTq8XlmyxZQorviknjA8Kp"},"executionInfo":{"elapsed":71278,"status":"ok","timestamp":1727495592238,"user":{"displayName":"Pham Phu Ngoc Trai (K16_HCM)","userId":"01599433814758632935"},"user_tz":-420},"id":"XobG67m2N_I9","outputId":"5b7eab00-e853-4cb6-a5e9-f15930ebcdc2"},"outputs":[{"name":"stdout","output_type":"stream","text":["Couldn't find program: 'bash'\n"]}],"source":["%%bash\n","# file PubTables-1M-Structure_Images_Val.tar.gz\n","# file PubTables-1M-Structure_Annotations_Val.tar.gz\n","# mkdir ./data\n","# tar -xvf PubTables-1M-Structure_Images_Val.tar.gz -C ./data/\n","# tar -xvf PubTables-1M-Structure_Annotations_Val.tar.gz -C ./data/"]},{"cell_type":"code","execution_count":61,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1727495605345,"user":{"displayName":"Pham Phu Ngoc Trai (K16_HCM)","userId":"01599433814758632935"},"user_tz":-420},"id":"SriUByfMVaIp"},"outputs":[],"source":["import os\n","import xml.etree.ElementTree as ET\n","from glob import glob\n","from PIL import Image\n","import shutil\n","import random\n","\n","\n","classes = [\n","    'table column', \n","    # 'table row', \n","    # 'table spanning cell', \n","    # 'table text cell'\n","]\n","\n","def convert_coordinates_to_polygon(size, points):\n","    width, height = size\n","    return [(float(x) / width, float(y) / height) for x, y in points]\n","\n","def convert_xml_to_yolo_segment(xml_file, output_dir, image_dir):\n","    tree = ET.parse(xml_file)\n","    root = tree.getroot()\n","\n","    filename = root.find('filename').text\n","    image_path = os.path.join(image_dir, filename)\n","    \n","    # Read image dimensions using PIL\n","    with Image.open(image_path) as img:\n","        width, height = img.size\n","\n","    output_filename = os.path.splitext(filename)[0] + '.txt'\n","    with open(os.path.join(output_dir, output_filename), 'w') as out_file:\n","        for obj in root.iter('object'):\n","            cls = obj.find('name').text\n","            if cls not in classes:\n","                continue\n","\n","            cls_id = classes.index(cls)\n","\n","            xmlbox = obj.find('bndbox')\n","            xmin = float(xmlbox.find('xmin').text) / width\n","            ymin = float(xmlbox.find('ymin').text) / height\n","            xmax = float(xmlbox.find('xmax').text) / width\n","            ymax = float(xmlbox.find('ymax').text) / height\n","            \n","            # Create a polygon with 4 points (rectangle corners)\n","            points = [\n","                (xmin, ymin),  # Top-left\n","                (xmax, ymin),  # Top-right\n","                (xmax, ymax),  # Bottom-right\n","                (xmin, ymax)   # Bottom-left\n","            ]\n","            \n","            # Format the points as a string\n","            points_str = ' '.join([f'{x:.6f} {y:.6f}' for x, y in points])\n","            \n","            out_file.write(f\"{cls_id} {points_str}\\n\")\n","\n","# Update the process_directory function to include the image_dir parameter\n","def process_directory(input_dir, output_dir, image_dir, nfiles = \"all\"):\n","    if not os.path.exists(output_dir):\n","        os.makedirs(output_dir)\n","\n","    xml_files = glob(os.path.join(input_dir, '*.xml'))\n","\n","    if nfiles != \"all\":\n","        xml_files = random.sample(xml_files, nfiles)\n","\n","    for xml_file in xml_files:\n","        convert_xml_to_yolo_segment(xml_file, output_dir, image_dir)\n","\n","def copy_corresponding_images(input_dir, image_dir, output_dir):\n","    # Get all YOLO annotation files in the output directory\n","    yolo_files = glob(os.path.join(input_dir, '*.txt'))\n","\n","    for yolo_file in yolo_files:\n","        # Get the base filename without extension\n","        base_name = os.path.splitext(os.path.basename(yolo_file))[0]\n","\n","        # Look for corresponding image file (supporting common image formats)\n","        for ext in ['.jpg', '.jpeg', '.png', '.bmp']:\n","            image_file = os.path.join(image_dir, base_name + ext)\n","            if os.path.exists(image_file):\n","                # Copy the image to the output directory\n","                shutil.copy(image_file, output_dir)\n","                break  # Stop searching once the image is found and copied"]},{"cell_type":"code","execution_count":62,"metadata":{"id":"1yT3AxWVzVoJ"},"outputs":[],"source":["import os\n","import yaml\n","\n","def create_dataset_yaml(dataset_dir, yaml_path):\n","  # Create the dataset structure\n","  dataset = {\n","      'path': os.path.abspath(dataset_dir),\n","      'train': 'train',  # Assuming all data is for training\n","      'val': 'val',    # Using same data for validation\n","    #   'test': 'train',   # Using same data for testing\n","      'names': {i: name for i, name in enumerate(classes)},\n","      'nc': len(classes)\n","  }\n","\n","  # Write the YAML file\n","  with open(yaml_path, 'w') as file:\n","      yaml.dump(dataset, file, default_flow_style=False)\n","\n","  print(f\"Dataset YAML file created at: {yaml_path}\")"]},{"cell_type":"code","execution_count":63,"metadata":{"executionInfo":{"elapsed":700,"status":"ok","timestamp":1727495798639,"user":{"displayName":"Pham Phu Ngoc Trai (K16_HCM)","userId":"01599433814758632935"},"user_tz":-420},"id":"VeksJj1gYXVr"},"outputs":[{"name":"stdout","output_type":"stream","text":["Dataset YAML file created at: D:\\.Capstone\\workspace\\dataset\\dataset.yaml\n"]}],"source":["import os\n","\n","data_dir = r\"D:\\.Capstone\\workspace\\data\"\n","dataset_dir = r\"D:\\.Capstone\\workspace\\dataset\"\n","\n","# Create main dataset directory\n","os.makedirs(dataset_dir, exist_ok=True)\n","\n","# Create train directories\n","train_images_dir = os.path.join(dataset_dir, \"train\", \"images\")\n","train_label_dir = os.path.join(dataset_dir, \"train\", \"labels\")\n","os.makedirs(train_images_dir, exist_ok=True)\n","os.makedirs(train_label_dir, exist_ok=True)\n","\n","# Create validation directories\n","val_images_dir = os.path.join(dataset_dir, \"val\", \"images\")\n","val_label_dir = os.path.join(dataset_dir, \"val\", \"labels\")\n","os.makedirs(val_images_dir, exist_ok=True)\n","os.makedirs(val_label_dir, exist_ok=True)\n","\n","image_dir = r\"D:\\.Capstone\\workspace\\data\\PubTables-1M-Structure_Images_Val\"\n","process_directory(r\"D:\\.Capstone\\workspace\\data\\PubTables-1M-Structure_Annotations_Val\", \n","                  train_label_dir, \n","                  image_dir, \n","                  nfiles=1800)\n","process_directory(r\"D:\\.Capstone\\workspace\\data\\PubTables-1M-Structure_Annotations_Val\", \n","                  val_label_dir, \n","                  image_dir, \n","                  nfiles=200)\n","\n","copy_corresponding_images(train_label_dir, r\"D:\\.Capstone\\workspace\\data\\PubTables-1M-Structure_Images_Val\", train_images_dir)\n","copy_corresponding_images(val_label_dir, r\"D:\\.Capstone\\workspace\\data\\PubTables-1M-Structure_Images_Val\", val_images_dir)\n","\n","create_dataset_yaml(dataset_dir, os.path.join(dataset_dir, \"dataset.yaml\"))"]},{"cell_type":"markdown","metadata":{},"source":["## Visualize the data"]},{"cell_type":"code","execution_count":60,"metadata":{},"outputs":[{"ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'D:\\\\.Capstone\\\\workspace\\\\dataset\\\\dataset.yaml'","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","Cell \u001b[1;32mIn[60], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcolorsys\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;66;03m# Load the dataset configuration\u001b[39;00m\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43m.Capstone\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mworkspace\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdataset\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mdataset.yaml\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m file:\n\u001b[0;32m     10\u001b[0m     dataset_config \u001b[38;5;241m=\u001b[39m yaml\u001b[38;5;241m.\u001b[39msafe_load(file)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Get the dataset path and class names\u001b[39;00m\n","File \u001b[1;32mc:\\Users\\jayll\\miniconda3\\envs\\capstone\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'D:\\\\.Capstone\\\\workspace\\\\dataset\\\\dataset.yaml'"]}],"source":["import yaml\n","import cv2\n","import matplotlib.pyplot as plt\n","import random\n","import os\n","import colorsys\n","\n","# Load the dataset configuration\n","with open(r\"D:\\.Capstone\\workspace\\dataset\\dataset.yaml\", 'r') as file:\n","    dataset_config = yaml.safe_load(file)\n","\n","# Get the dataset path and class names\n","dataset_path = dataset_config['path']\n","class_names = dataset_config['names']\n","\n","# Choose a random set (train or val)\n","image_set = random.choice(['train', 'val'])\n","images_path = os.path.join(dataset_path, image_set, 'images')\n","\n","# Get a list of all image files\n","image_files = [f for f in os.listdir(images_path) if f.endswith(('.jpg', '.jpeg', '.png'))]\n","\n","# Choose a random image\n","random_image = random.choice(image_files)\n","image_path = os.path.join(images_path, random_image)\n","\n","# Load the image\n","image = cv2.imread(image_path)\n","image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n","\n","# Load the corresponding label file\n","label_path = os.path.join(dataset_path, image_set, 'labels', random_image.rsplit('.', 1)[0] + '.txt')\n","\n","# Read and parse the label file\n","with open(label_path, 'r') as file:\n","    labels = file.readlines()\n","\n","# Get image dimensions\n","height, width, _ = image.shape\n","\n","# Function to generate distinct colors\n","def generate_colors(n):\n","    hsv_tuples = [(x / n, 1., 1.) for x in range(n)]\n","    return list(map(lambda x: tuple(round(i * 255) for i in colorsys.hsv_to_rgb(*x)), hsv_tuples))\n","\n","# Generate a color for each class\n","colors = generate_colors(len(class_names))\n","\n","# Draw bounding boxes and labels\n","for label in labels:\n","    class_id, *points = map(float, label.strip().split())\n","    \n","    # Convert normalized coordinates to pixel coordinates\n","    pixel_points = [(int(x * width), int(y * height)) for x, y in zip(points[::2], points[1::2])]\n","    \n","    # Get color for this class\n","    color = colors[int(class_id)]\n","    \n","    # Draw polygon\n","    cv2.polylines(image, [np.array(pixel_points)], isClosed=True, color=color, thickness=2)\n","\n","# Display the image\n","plt.figure(figsize=(12, 8))\n","plt.imshow(image)\n","plt.axis('off')\n","plt.title(f\"Random Image: {random_image}\")\n","plt.show()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyN2ntujhhDCs6lH3Ua3MRMw","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.10"}},"nbformat":4,"nbformat_minor":0}
